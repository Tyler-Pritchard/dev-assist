import logging
from utils.model_loader import ModelLoader

class CodeAnalysisService:
    def __init__(self):
        # Initialize the model loader with the desired model
        self.model_loader = ModelLoader("facebook/incoder-1B")
        self.device = self.model_loader.device
        self.model, self.tokenizer = self.model_loader.get_model()

    def analyze_code(self, code: str) -> str:
        """
        Analyze the given code for insights.

        Args:
            code (str): The code snippet to analyze.

        Returns:
            str: Analysis results.
        """
        try:
            logging.info("Analyzing code input")
            prompt = f"""
            You are a professional Python code reviewer. Analyze the following function:
            - Identify specific errors or potential issues.
            - Provide suggestions for improving readability, validation, or naming.
            - Comment on adherence to Python best practices (readability, efficiency, clarity).
            Focus strictly on the provided function and avoid unrelated examples or testing scenarios.

            Function:
            {code}
            """
            # Encode the input
            input_ids = self.tokenizer.encode(prompt, return_tensors="pt").to(self.device)
            
            # Generate the analysis
            output = self.model.generate(
                input_ids,
                max_new_tokens=150,  # Limit output length to reduce verbosity
                pad_token_id=self.tokenizer.pad_token_id,
                temperature=0.7,  # Balanced randomness for creativity and focus
                top_p=0.9,  # Nucleus sampling for diversity
                num_beams=4,  # Ensure coherent generation
                repetition_penalty=1.2,  # Penalize repetitive patterns
                early_stopping=True,  # Stop at a reasonable output length
            )
            # Decode and clean the analysis result
            analysis = self.tokenizer.decode(output[0], skip_special_tokens=True)
            processed_analysis = self._clean_analysis_output(analysis)
            logging.info(f"Cleaned analysis result: {processed_analysis}")
            return processed_analysis.strip()
        except Exception as e:
            logging.error(f"Error analyzing code: {e}")
            return "Error analyzing code."

    def _clean_analysis_output(self, output: str) -> str:
        """
        Cleans the generated analysis output by removing duplicates and artifacts.

        Args:
            output (str): The raw output generated by the model.

        Returns:
            str: Cleaned and formatted analysis output.
        """
        lines = output.split("\n")
        filtered_lines = []
        for line in lines:
            line = line.strip()
            # Filter lines with irrelevant examples or invalid content
            if ">>>" not in line and not line.startswith("Examples:"):
                filtered_lines.append(line)
        return "\n".join(filtered_lines)
